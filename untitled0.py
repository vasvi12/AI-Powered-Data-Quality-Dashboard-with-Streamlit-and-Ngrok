# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a41BwJciq7Mqoka_GHu6YcG9h1K0WsHg
"""

import pandas as pd

# Load the CSV file
df = pd.read_csv('/content/ai_data_quality_dataset.csv')

# Show number of rows and columns
print(f"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.")

# Display first 5 rows
print(df.head())

# Check for missing values
missing_values = df.isnull().sum()

# Display the count of missing values per column
print("Missing values in each column:")
print(missing_values)

# Check for unexpected nulls or zero values in sales_amount
unexpected_values = df[(df['sales_amount'].isnull()) | (df['sales_amount'] == 0)]

# Count the unexpected values
unexpected_count = unexpected_values.shape[0]

# Display the count and the unexpected values
print(f"Unexpected nulls or zero values in sales_amount: {unexpected_count}")
print(unexpected_values)

# Check for duplicate records based on customer_id and order_date
duplicates = df[df.duplicated(subset=['customer_id', 'order_date'], keep=False)]

# Count the number of duplicate records
duplicate_count = duplicates.shape[0]

# Display the count and the duplicate records
print(f"Number of duplicate records found: {duplicate_count}")
print(duplicates)

import re

# Function to validate email format
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return re.match(email_regex, email) is not None

# Function to validate phone number format (assuming US format)
def is_valid_phone(phone):
    phone_regex = r'^\d{3}-\d{3}-\d{4}$'
    return re.match(phone_regex, phone) is not None

# Validate email and phone number formats
invalid_emails = df[~df['email'].apply(is_valid_email)]
invalid_phones = df[~df['phone_number'].apply(is_valid_phone)]

# Count invalid formats
invalid_email_count = invalid_emails.shape[0]
invalid_phone_count = invalid_phones.shape[0]

# Display the counts and the invalid records
print(f"Invalid email addresses: {invalid_email_count}")
print(invalid_emails)

print(f"Invalid phone numbers: {invalid_phone_count}")
print(invalid_phones)

# Convert order_date to datetime format
df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')

# Group by order_date and sum sales_amount
daily_sales = df.groupby('order_date')['sales_amount'].sum().reset_index()

# Calculate percentage change in sales
daily_sales['percentage_change'] = daily_sales['sales_amount'].pct_change() * 100

# Identify significant changes (e.g., greater than 20% increase or decrease)
significant_changes = daily_sales[(daily_sales['percentage_change'].abs() > 20)]

# Display the results
print("Significant changes in daily sales:")
print(significant_changes)

!pip install streamlit
!pip install pyngrok

from pyngrok import ngrok

# Replace 'YOUR_AUTH_TOKEN' with your actual ngrok auth token
ngrok.set_auth_token('2wtBxJX44I2yFaJUuwKjg4Kd8DS_4RW9sSpTLjwT3K1FeDH8w')

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

@st.cache_data
def load_data():
    df = pd.read_csv('/content/ai_data_quality_dataset.csv')
    df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')
    return df

df = load_data()

st.title('Comprehensive Data Quality Dashboard')
st.write(f"Dataset Overview: {df.shape[0]} rows and {df.shape[1]} columns.")

# Missing Values Analysis
st.header('Missing Values Analysis')

# Missing values table and counts
missing_counts = df.isnull().sum()
missing_df = missing_counts.reset_index()
missing_df.columns = ['Column', 'Missing Count']
missing_df['Missing Percent'] = (missing_df['Missing Count'] / len(df)) * 100

st.subheader('Missing Values Table')
st.dataframe(missing_df)

# Bar chart for missing values
st.subheader('Missing Values Bar Chart')
fig1, ax1 = plt.subplots(figsize=(8, 4))
sns.barplot(x='Column', y='Missing Count', data=missing_df, palette='rocket', ax=ax1)
ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)
st.pyplot(fig1)

# Heatmap of missing values
st.subheader('Missing Values Heatmap')
fig2, ax2 = plt.subplots(figsize=(12, 5))
sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='mako', ax=ax2)
st.pyplot(fig2)

# Pie charts per column for missing vs present
st.subheader('Missing vs Present Values Pie Charts')
for col in df.columns:
    counts = df[col].isnull().value_counts()
    labels = ['Present', 'Missing']
    sizes = [counts.get(False, 0), counts.get(True, 0)]
    fig, ax = plt.subplots()
    ax.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['#2ca02c', '#d62728'], startangle=90)
    ax.axis('equal')
    st.write(f"Column: {col}")
    st.pyplot(fig)

# Duplicate Records Analysis
st.header('Duplicate Records')

duplicate_rows = df[df.duplicated(subset=['customer_id', 'order_date'], keep=False)]
dupe_count = duplicate_rows.shape[0]

st.write(f"Duplicate records count based on customer_id & order_date: {dupe_count}")

if dupe_count > 0:
    st.subheader('Duplicate Records Table')
    st.dataframe(duplicate_rows)

# Sales Amount Distribution and Trend
st.header('Sales Amount Analysis')

# Summary stats
st.subheader('Descriptive Statistics')
desc_stats = df['sales_amount'].describe()
st.write(desc_stats)

# Histogram and Boxplot side by side
fig3, (ax3, ax4) = plt.subplots(1,2, figsize=(12,4))
sns.histplot(df['sales_amount'].dropna(), bins=30, kde=True, color='deepskyblue', ax=ax3)
ax3.set_title('Sales Amount Histogram')

sns.boxplot(x=df['sales_amount'], color='lightgreen', ax=ax4)
ax4.set_title('Sales Amount Boxplot')

st.pyplot(fig3)

# Sales over time line chart
st.subheader('Daily Sales Amount Over Time')
daily_sales = df.groupby('order_date')['sales_amount'].sum().reset_index()
fig4, ax5 = plt.subplots(figsize=(12,4))
sns.lineplot(data=daily_sales, x='order_date', y='sales_amount', marker='o', ax=ax5)
ax5.set_title('Daily Sales Amount')
plt.xticks(rotation=45)
st.pyplot(fig4)

!ls -l data_quality_dashboard.py

from pyngrok import ngrok
import time

# If you haven't set your ngrok token before, do it here:
# ngrok.set_auth_token('your_actual_auth_token_here')

# Connect to ngrok tunnel on port 8501
public_url = ngrok.connect(8501, "http")
print(f"Streamlit URL: {public_url}")

# Run the Streamlit app
!streamlit run data_quality_dashboard.py &
time.sleep(5)

# Install dependencies (if not already available)
!pip install seaborn matplotlib pandas --quiet

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load data
df = pd.read_csv('/content/ai_data_quality_dataset.csv')
df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')

# Overview
print(f"Dataset Overview: {df.shape[0]} rows and {df.shape[1]} columns\n")
print(df.head())

# --- Missing Values Analysis ---
missing_counts = df.isnull().sum()
missing_df = missing_counts.reset_index()
missing_df.columns = ['Column', 'Missing Count']
missing_df['Missing Percent'] = (missing_df['Missing Count'] / len(df)) * 100

# Table
print("\nMissing Values Table:\n", missing_df)

# Bar Chart
plt.figure(figsize=(10, 5))
sns.barplot(x='Column', y='Missing Count', data=missing_df, palette='rocket')
plt.xticks(rotation=45)
plt.title('Missing Values Count per Column')
plt.tight_layout()
plt.show()

# Heatmap
plt.figure(figsize=(12, 5))
sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='mako')
plt.title('Missing Value Heatmap')
plt.tight_layout()
plt.show()

# Pie charts per column
for col in df.columns:
    counts = df[col].isnull().value_counts()
    labels = ['Present', 'Missing']
    sizes = [counts.get(False, 0), counts.get(True, 0)]
    plt.figure()
    plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['#2ca02c', '#d62728'], startangle=90)
    plt.title(f"Missing vs Present for {col}")
    plt.axis('equal')
    plt.show()

# --- Duplicate Records Analysis ---
duplicate_rows = df[df.duplicated(subset=['customer_id', 'order_date'], keep=False)]
print(f"\nDuplicate records count based on customer_id & order_date: {duplicate_rows.shape[0]}")
if not duplicate_rows.empty:
    print("\nDuplicate Rows:\n", duplicate_rows)

# --- Sales Amount Distribution ---
desc_stats = df['sales_amount'].describe()
print("\nDescriptive Statistics for Sales Amount:\n", desc_stats)

# Histogram and Boxplot
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
sns.histplot(df['sales_amount'].dropna(), bins=30, kde=True, color='deepskyblue', ax=ax1)
ax1.set_title('Sales Amount Histogram')

sns.boxplot(x=df['sales_amount'], color='lightgreen', ax=ax2)
ax2.set_title('Sales Amount Boxplot')

plt.tight_layout()
plt.show()

# --- Daily Sales Trend ---
daily_sales = df.groupby('order_date')['sales_amount'].sum().reset_index()
plt.figure(figsize=(12, 4))
sns.lineplot(data=daily_sales, x='order_date', y='sales_amount', marker='o')
plt.title('Daily Sales Amount Over Time')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# --- Correlation Matrix ---
numeric_cols = df.select_dtypes(include=np.number)
if not numeric_cols.empty:
    corr = numeric_cols.corr()
    plt.figure(figsize=(10, 6))
    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
    plt.title("Correlation Matrix of Numeric Features")
    plt.tight_layout()
    plt.show()

# --- Frequent Values in Categorical Columns ---
cat_cols = df.select_dtypes(include='object').columns
for col in cat_cols:
    top_vals = df[col].value_counts().head(10)
    if not top_vals.empty:
        plt.figure(figsize=(8, 4))
        sns.barplot(x=top_vals.values, y=top_vals.index, palette='viridis')
        plt.title(f'Top 10 Values in {col}')
        plt.tight_layout()
        plt.show()

# --- Boxplots for Numeric Columns ---
num_cols = df.select_dtypes(include=np.number).columns
for col in num_cols:
    plt.figure(figsize=(6, 4))
    sns.boxplot(x=df[col], color='orange')
    plt.title(f'Boxplot of {col}')
    plt.tight_layout()
    plt.show()

# --- Rows with Most Missing Values ---
df['missing_count'] = df.isnull().sum(axis=1)
top_missing_rows = df.sort_values(by='missing_count', ascending=False).head(10)
print("\nTop 10 Rows with Most Missing Values:\n", top_missing_rows.drop(columns='missing_count'))

# --- Monthly Sales Trend ---
monthly_sales = df.set_index('order_date').resample('M')['sales_amount'].sum()
plt.figure(figsize=(10, 4))
monthly_sales.plot(marker='o')
plt.title("Monthly Sales Trend")
plt.ylabel("Sales Amount")
plt.tight_layout()
plt.show()

# --- Top Customers by Sales ---
top_customers = df.groupby('customer_id')['sales_amount'].sum().nlargest(10)
plt.figure(figsize=(8, 5))
sns.barplot(x=top_customers.values, y=top_customers.index, palette='Blues_r')
plt.title("Top 10 Customers by Total Sales")
plt.xlabel("Total Sales Amount")
plt.ylabel("Customer ID")
plt.tight_layout()
plt.show()

app_code = """
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

st.set_page_config(layout="wide")
sns.set_style("whitegrid")

@st.cache_data
def load_data():
    df = pd.read_csv('/content/ai_data_quality_dataset.csv')
    df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')
    return df

df = load_data()

st.title('📊 Comprehensive Data Quality Dashboard')
st.write(f"✅ Dataset contains `{df.shape[0]}` rows and `{df.shape[1]}` columns.")

# --------------------------
# Missing Values Analysis
# --------------------------
st.header('🟡 Missing Values Analysis')

missing_counts = df.isnull().sum()
missing_df = missing_counts.reset_index()
missing_df.columns = ['Column', 'Missing Count']
missing_df['Missing Percent'] = (missing_df['Missing Count'] / len(df)) * 100
missing_df = missing_df[missing_df['Missing Count'] > 0]

st.subheader('📋 Missing Values Table')
st.dataframe(missing_df)

st.subheader('📊 Missing Values Bar Chart')
fig1, ax1 = plt.subplots(figsize=(10, 4))
sns.barplot(x='Column', y='Missing Count', data=missing_df, palette='rocket', ax=ax1)
ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)
st.pyplot(fig1)
plt.close(fig1)

st.subheader('🌡️ Missing Values Heatmap')
fig2, ax2 = plt.subplots(figsize=(12, 5))
sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='mako', ax=ax2)
st.pyplot(fig2)
plt.close(fig2)

st.subheader('🥧 Missing vs Present Pie Charts')
for col in missing_df['Column']:
    counts = df[col].isnull().value_counts()
    sizes = [counts.get(False, 0), counts.get(True, 0)]
    labels = ['Present', 'Missing']

    fig, ax = plt.subplots()
    ax.pie(sizes, labels=labels, autopct='%1.1f%%',
           colors=['#2ca02c', '#d62728'], startangle=90)
    ax.axis('equal')
    st.write(f"**Column: {col}**")
    st.pyplot(fig)
    plt.close(fig)

# --------------------------
# Duplicate Records Analysis
# --------------------------
st.header('🧾 Duplicate Records')

duplicate_rows = df[df.duplicated(subset=['customer_id', 'order_date'], keep=False)]
dupe_count = duplicate_rows.shape[0]
st.write(f"Found **{dupe_count}** duplicate records based on `customer_id` and `order_date`.")

if dupe_count > 0:
    st.subheader('📄 Duplicate Records Table')
    st.dataframe(duplicate_rows)

# --------------------------
# Sales Amount Analysis
# --------------------------
st.header('💰 Sales Amount Analysis')

st.subheader('📊 Descriptive Statistics')
st.write(df['sales_amount'].describe())

st.subheader('📉 Histogram and Boxplot of Sales Amount')
fig3, (ax3, ax4) = plt.subplots(1, 2, figsize=(12, 4))
sns.histplot(df['sales_amount'].dropna(), bins=30, kde=True, color='deepskyblue', ax=ax3)
ax3.set_title('Sales Amount Histogram')

sns.boxplot(x=df['sales_amount'], color='lightgreen', ax=ax4)
ax4.set_title('Sales Amount Boxplot')

st.pyplot(fig3)
plt.close(fig3)

st.subheader('📈 Daily Sales Trend Over Time')
daily_sales = df.groupby('order_date')['sales_amount'].sum().reset_index()
fig4, ax5 = plt.subplots(figsize=(12, 4))
sns.lineplot(data=daily_sales, x='order_date', y='sales_amount', marker='o', ax=ax5)
ax5.set_title('Daily Sales Amount')
plt.xticks(rotation=45)
st.pyplot(fig4)
plt.close(fig4)

st.markdown("---")
st.caption("Dashboard powered by Streamlit | Developed in Google Colab with ngrok")
"""

with open("streamlit_dashboard.py", "w") as file:
    file.write(app_code)

print("✅ Streamlit app saved as 'streamlit_dashboard.py'")

# Step 1: Install dependencies
!pip install -q streamlit pyngrok

# Step 2: Save Streamlit app code (already done earlier)
# If not yet saved, rerun the previous cell

# Step 3: Launch streamlit app via ngrok
from pyngrok import ngrok
import subprocess
import threading

# Kill previous tunnels if any
ngrok.kill()

# Open HTTP tunnel on port 8501
public_url = ngrok.connect(8501)
print(f"🚀 Streamlit app running at: {public_url}")

# Step 4: Run Streamlit in background thread
def run_app():
    subprocess.run(["streamlit", "run", "streamlit_dashboard.py"])

thread = threading.Thread(target=run_app)
thread.start()